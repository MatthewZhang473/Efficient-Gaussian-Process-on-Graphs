{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbd73c1",
   "metadata": {},
   "source": [
    "# Random Graph Generation and Random Walk\n",
    "\n",
    "Simple implementation using SciPy and NetworkX to:\n",
    "1. Generate a random sparse graph\n",
    "2. Calculate the graph Laplacian\n",
    "3. Perform a random walk using the Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5788e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import expm_multiply\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "N = 100          # Number of nodes\n",
    "AVG_DEGREE = 5   # Average degree per node\n",
    "M = 10           # Number of random walk steps\n",
    "START_NODE = 0   # Starting node for random walk\n",
    "SEED = 42        # Random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2ef375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generating random sparse graph...\n",
      "Generated graph with 100 nodes and 227 edges\n",
      "Actual average degree: 4.54\n"
     ]
    }
   ],
   "source": [
    "def generate_random_graph(n_nodes, avg_degree, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a random sparse graph using Erdős-Rényi model.\n",
    "    \n",
    "    Time complexity: O(N²) in worst case, O(N * avg_degree) on average\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Calculate edge probability to achieve desired average degree\n",
    "    p = avg_degree / (n_nodes - 1)\n",
    "    \n",
    "    # Generate random graph\n",
    "    G = nx.erdos_renyi_graph(n_nodes, p, seed=seed)\n",
    "    \n",
    "    # Ensure graph is connected (add edges if needed)\n",
    "    if not nx.is_connected(G):\n",
    "        components = list(nx.connected_components(G))\n",
    "        for i in range(len(components) - 1):\n",
    "            node1 = list(components[i])[0]\n",
    "            node2 = list(components[i + 1])[0]\n",
    "            G.add_edge(node1, node2)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Step 1: Generate random sparse graph\n",
    "print(\"Step 1: Generating random sparse graph...\")\n",
    "G = generate_random_graph(N, AVG_DEGREE, SEED)\n",
    "print(f\"Generated graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "print(f\"Actual average degree: {2 * G.number_of_edges() / G.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e018b1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2-3: Computing normalized graph Laplacian...\n",
      "Normalized Laplacian: L = I - D^(-1/2) * A * D^(-1/2)\n",
      "Laplacian matrix shape: (100, 100)\n",
      "Laplacian sparsity: 5.54% non-zero entries\n",
      "Laplacian matrix type: <class 'scipy.sparse._csr.csr_array'>\n",
      "Time complexity: O(E) = O(227) = O(N × avg_degree)\n"
     ]
    }
   ],
   "source": [
    "def compute_graph_laplacian(graph):\n",
    "    \"\"\"\n",
    "    Compute the normalized graph Laplacian matrix: L = I - D^(-1/2) * A * D^(-1/2)\n",
    "    \n",
    "    Time complexity: O(E) = O(N * avg_degree)\n",
    "    \"\"\"\n",
    "    # Get the normalized Laplacian matrix as sparse matrix\n",
    "    # This computes L = I - D^(-1/2) * A * D^(-1/2)\n",
    "    L = nx.normalized_laplacian_matrix(graph, nodelist=sorted(graph.nodes()))\n",
    "    return L\n",
    "\n",
    "# Step 2 & 3: Load with NetworkX and calculate Laplacian\n",
    "print(\"\\nStep 2-3: Computing normalized graph Laplacian...\")\n",
    "print(\"Normalized Laplacian: L = I - D^(-1/2) * A * D^(-1/2)\")\n",
    "L = compute_graph_laplacian(G)\n",
    "print(f\"Laplacian matrix shape: {L.shape}\")\n",
    "print(f\"Laplacian sparsity: {L.nnz / (N * N) * 100:.2f}% non-zero entries\")\n",
    "print(f\"Laplacian matrix type: {type(L)}\")\n",
    "print(f\"Time complexity: O(E) = O({G.number_of_edges()}) = O(N × avg_degree)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d58a5",
   "metadata": {},
   "source": [
    "## Time Complexity Analysis\n",
    "\n",
    "For a graph with **N = 100 nodes** and **average degree = 5**:\n",
    "\n",
    "### 1. Graph Generation: **O(N²)** worst case, **O(N × avg_degree)** average\n",
    "- Erdős-Rényi model checks all possible edges: O(N²) = O(10,000)\n",
    "- Expected edges created: O(N × avg_degree) = O(500)\n",
    "- **Actual complexity: O(500)** on average\n",
    "\n",
    "### 2. NetworkX Loading: **O(E)** \n",
    "- Already in NetworkX format, no additional loading needed\n",
    "- **Complexity: O(1)**\n",
    "\n",
    "### 3. Laplacian Computation: **O(E)**\n",
    "- Building adjacency matrix: O(E) = O(N × avg_degree) = O(500)\n",
    "- Computing normalized Laplacian: O(E) = O(500)\n",
    "- **Total complexity: O(500)**\n",
    "\n",
    "### 4. Uniform Random Walk: **O(M × avg_degree)**\n",
    "- Each step: get neighbors O(avg_degree), sample uniformly O(1)\n",
    "- For M = 10 steps: O(10 × 5) = **O(50)**\n",
    "- **Most efficient approach for traditional random walks**\n",
    "\n",
    "### Overall Time Complexity: **O(M × avg_degree) = O(50)**\n",
    "\n",
    "The uniform neighbor visiting strategy provides the standard random walk behavior where each step moves to a uniformly random neighbor of the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3da8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalkSampler:\n",
    "    \"\"\"\n",
    "    Random walk sampler with configurable strategies and batch sampling support.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, graph, strategy='uniform', stopping_prob=0.0, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize the random walk sampler.\n",
    "        \n",
    "        Args:\n",
    "            graph: NetworkX graph object\n",
    "            strategy: Sampling strategy ('uniform' for now, extensible for future strategies)\n",
    "            stopping_prob: Probability of stopping at each step (0.0 = never stop early)\n",
    "            seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "        self.strategy = strategy\n",
    "        self.stopping_prob = stopping_prob\n",
    "        self.seed = seed\n",
    "        \n",
    "        if strategy not in ['uniform']:\n",
    "            raise ValueError(f\"Strategy '{strategy}' not supported. Available: ['uniform']\")\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "    \n",
    "    def sample_walk(self, start_node, max_steps):\n",
    "        \"\"\"\n",
    "        Sample a single random walk from a starting node.\n",
    "        \n",
    "        Args:\n",
    "            start_node: Starting node index\n",
    "            max_steps: Maximum number of steps (may stop early due to stopping_prob)\n",
    "        \n",
    "        Returns:\n",
    "            list: Path of visited nodes\n",
    "        \"\"\"\n",
    "        if self.strategy == 'uniform':\n",
    "            return self._uniform_walk(start_node, max_steps)\n",
    "        \n",
    "    def sample_batch_walks(self, start_nodes, max_steps, num_walks_per_node=1):\n",
    "        \"\"\"\n",
    "        Sample multiple random walks from multiple starting nodes.\n",
    "        \n",
    "        Args:\n",
    "            start_nodes: List of starting node indices or 'all' for all nodes\n",
    "            max_steps: Maximum number of steps per walk\n",
    "            num_walks_per_node: Number of walks to sample from each starting node\n",
    "        \n",
    "        Returns:\n",
    "            dict: {start_node: [walk1, walk2, ...]} where each walk is a list of nodes\n",
    "        \"\"\"\n",
    "        if start_nodes == 'all':\n",
    "            start_nodes = list(self.graph.nodes())\n",
    "        \n",
    "        batch_results = {}\n",
    "        \n",
    "        for start_node in start_nodes:\n",
    "            walks = []\n",
    "            for _ in range(num_walks_per_node):\n",
    "                walk = self.sample_walk(start_node, max_steps)\n",
    "                walks.append(walk)\n",
    "            batch_results[start_node] = walks\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def _uniform_walk(self, start_node, max_steps):\n",
    "        \"\"\"\n",
    "        Perform uniform random walk with stopping criteria.\n",
    "        \n",
    "        Time complexity: O(max_steps * avg_degree) in worst case\n",
    "        \"\"\"\n",
    "        current_node = start_node\n",
    "        path = [current_node]\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Check stopping criteria\n",
    "            if np.random.random() < self.stopping_prob:\n",
    "                break\n",
    "            \n",
    "            # Get neighbors of current node\n",
    "            neighbors = list(self.graph.neighbors(current_node))\n",
    "            \n",
    "            if len(neighbors) == 0:\n",
    "                # If isolated node, stop the walk\n",
    "                break\n",
    "            else:\n",
    "                # Uniformly sample from neighbors\n",
    "                next_node = np.random.choice(neighbors)\n",
    "                path.append(next_node)\n",
    "                current_node = next_node\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def get_walk_statistics(self, walks_dict):\n",
    "        \"\"\"\n",
    "        Compute statistics for batch walks.\n",
    "        \n",
    "        Args:\n",
    "            walks_dict: Output from sample_batch_walks\n",
    "        \n",
    "        Returns:\n",
    "            dict: Statistics about the walks\n",
    "        \"\"\"\n",
    "        total_walks = sum(len(walks) for walks in walks_dict.values())\n",
    "        total_steps = sum(len(walk) - 1 for walks in walks_dict.values() for walk in walks)\n",
    "        avg_walk_length = total_steps / total_walks if total_walks > 0 else 0\n",
    "        \n",
    "        all_nodes_visited = set()\n",
    "        for walks in walks_dict.values():\n",
    "            for walk in walks:\n",
    "                all_nodes_visited.update(walk)\n",
    "        \n",
    "        return {\n",
    "            'total_walks': total_walks,\n",
    "            'total_steps': total_steps,\n",
    "            'avg_walk_length': avg_walk_length,\n",
    "            'unique_nodes_visited': len(all_nodes_visited),\n",
    "            'graph_coverage': len(all_nodes_visited) / self.graph.number_of_nodes()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7804d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Using RandomWalkSampler for random walks...\n",
      "\n",
      "Single walk from node 0:\n",
      "Walk path: [0, 42, 59, 30, 32, 96, 78, 90, 76]\n",
      "Walk length: 9 steps\n",
      "\n",
      "Batch walks from first 5 nodes (2 walks each):\n",
      "Node 0: 2 walks\n",
      "  Walk 1: [0, 2, 75] (length: 3)\n",
      "  Walk 2: [0] (length: 1)\n",
      "Node 1: 2 walks\n",
      "  Walk 1: [1, 29, 81, 29, 27, 36, 27] (length: 7)\n",
      "  Walk 2: [1, 3, 7, 64, 7, 3, 52, 75, 89, 75, 12] (length: 11)\n",
      "Node 2: 2 walks\n",
      "  Walk 1: [2, 75, 71, 58] (length: 4)\n",
      "  Walk 2: [2, 75, 42, 75] (length: 4)\n",
      "Node 3: 2 walks\n",
      "  Walk 1: [3, 1, 3, 7, 64, 58, 71, 67, 20, 67, 81] (length: 11)\n",
      "  Walk 2: [3, 34, 47] (length: 3)\n",
      "Node 4: 2 walks\n",
      "  Walk 1: [4, 9, 4, 30] (length: 4)\n",
      "  Walk 2: [4, 96, 78, 80, 88, 80, 34, 74, 34, 37] (length: 10)\n",
      "\n",
      "Batch walk statistics:\n",
      "- total_walks: 10\n",
      "- total_steps: 48\n",
      "- avg_walk_length: 4.800\n",
      "- unique_nodes_visited: 30\n",
      "- graph_coverage: 0.300\n",
      "\n",
      "Sampling from all nodes (1 walk each, max 5 steps):\n",
      "Total walks: 100\n",
      "Average walk length: 3.02\n",
      "Graph coverage: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create RandomWalkSampler and demonstrate usage\n",
    "print(f\"\\nStep 4: Using RandomWalkSampler for random walks...\")\n",
    "\n",
    "# Create sampler with stopping probability\n",
    "sampler = RandomWalkSampler(G, strategy='uniform', stopping_prob=0.1, seed=SEED)\n",
    "\n",
    "# Single walk example\n",
    "print(f\"\\nSingle walk from node {START_NODE}:\")\n",
    "single_walk = sampler.sample_walk(START_NODE, M)\n",
    "print(f\"Walk path: {single_walk}\")\n",
    "print(f\"Walk length: {len(single_walk)} steps\")\n",
    "\n",
    "# Batch walks example - sample from first 5 nodes\n",
    "print(f\"\\nBatch walks from first 5 nodes (2 walks each):\")\n",
    "batch_walks = sampler.sample_batch_walks(\n",
    "    start_nodes=list(range(5)), \n",
    "    max_steps=M, \n",
    "    num_walks_per_node=2\n",
    ")\n",
    "\n",
    "for start_node, walks in batch_walks.items():\n",
    "    print(f\"Node {start_node}: {len(walks)} walks\")\n",
    "    for i, walk in enumerate(walks):\n",
    "        print(f\"  Walk {i+1}: {walk} (length: {len(walk)})\")\n",
    "\n",
    "# Get statistics\n",
    "stats = sampler.get_walk_statistics(batch_walks)\n",
    "print(f\"\\nBatch walk statistics:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "# Example of sampling from all nodes (smaller batch for demo)\n",
    "print(f\"\\nSampling from all nodes (1 walk each, max 5 steps):\")\n",
    "sampler_all = RandomWalkSampler(G, strategy='uniform', stopping_prob=0.15, seed=SEED)\n",
    "all_walks = sampler_all.sample_batch_walks('all', max_steps=5, num_walks_per_node=1)\n",
    "all_stats = sampler_all.get_walk_statistics(all_walks)\n",
    "print(f\"Total walks: {all_stats['total_walks']}\")\n",
    "print(f\"Average walk length: {all_stats['avg_walk_length']:.2f}\")\n",
    "print(f\"Graph coverage: {all_stats['graph_coverage']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f1ef8",
   "metadata": {},
   "source": [
    "## RandomWalkSampler API\n",
    "\n",
    "The `RandomWalkSampler` class provides a clean API for random walk sampling:\n",
    "\n",
    "### Features:\n",
    "- **Strategy Selection**: Currently supports 'uniform', extensible for future strategies\n",
    "- **Stopping Criteria**: Configurable probability `p` to stop early at each step\n",
    "- **Batch Sampling**: Efficiently sample multiple walks from multiple nodes\n",
    "- **Statistics**: Built-in methods to analyze walk properties\n",
    "\n",
    "### Usage Examples:\n",
    "\n",
    "```python\n",
    "# Create sampler\n",
    "sampler = RandomWalkSampler(graph, strategy='uniform', stopping_prob=0.1)\n",
    "\n",
    "# Single walk\n",
    "walk = sampler.sample_walk(start_node=0, max_steps=10)\n",
    "\n",
    "# Batch walks from specific nodes\n",
    "batch = sampler.sample_batch_walks([0, 1, 2], max_steps=10, num_walks_per_node=5)\n",
    "\n",
    "# Sample from all nodes\n",
    "all_walks = sampler.sample_batch_walks('all', max_steps=10)\n",
    "\n",
    "# Get statistics\n",
    "stats = sampler.get_walk_statistics(batch)\n",
    "```\n",
    "\n",
    "### Time Complexity:\n",
    "- **Single walk**: O(max_steps × avg_degree)\n",
    "- **Batch walks**: O(num_nodes × num_walks_per_node × max_steps × avg_degree)\n",
    "- **All nodes**: O(N × num_walks_per_node × max_steps × avg_degree)\n",
    "\n",
    "The sampler efficiently handles large-scale random walk generation for graph analysis and machine learning applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
