{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Gaussian Random Field Inference on Graphs - Regression Task on Traffic Dataset\n",
    "\n",
    "This notebook contains the following:\n",
    "\n",
    "1. Showing the baseline performance using the exact diffusion kernel.\n",
    "2. Showing the similar level performance using Product of Feature Matrices (PoFM) kernel, compared across the parameter 'max_expansion' which determines the order of the approximation.\n",
    "3. Showing the convergence of the GRF to the PoFM kernel for 'max_expansion = 5'\n",
    "4. (Opt) Showing the performance of grf kernel with arbitrary modulation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 15:19:36.316868: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-16 15:19:36.329852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763306376.343573 2646675 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763306376.348173 2646675 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763306376.359093 2646675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763306376.359102 2646675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763306376.359104 2646675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763306376.359105 2646675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-16 15:19:36.362677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/gpflow/versions.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/gpflow/versions.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import networkx as nx\n",
    "from gpflow.utilities import print_summary\n",
    "import tensorflow_probability as tfp\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from efficient_graph_gp.graph_kernels import get_normalized_laplacian\n",
    "from efficient_graph_gp.gpflow_kernels import GraphDiffusionKernel\n",
    "from utils import compute_fro\n",
    "from traffic_utils.preprocessing import load_PEMS\n",
    "from traffic_utils.plotting import plot_PEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithms\t    efficient_graph_gp_sparse  presentations   requirements.txt\n",
      "Archive\t\t    experiments_dense\t       processed_data  setup.py\n",
      "data\t\t    experiments_sparse\t       __pycache__     utils.py\n",
      "efficient_graph_gp  graph_bo\t\t       README.md       venv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_dense/traffic_dataset/traffic_utils/preprocessing.py:90: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again as this compatibility may be removed in a future version of shapely.\n",
      "  G = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763306407.809028 2646675 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9615 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "I0000 00:00:1763306407.810563 2646675 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9611 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 1016)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the PEMS dataset\n",
    "\n",
    "np.random.seed(1111)\n",
    "num_eigenpairs = 500\n",
    "dataset = 'PeMS-Bay-new'\n",
    "num_train = 250\n",
    "\n",
    "G, data_train, data_test, data = load_PEMS(num_train=num_train)\n",
    "x_train, y_train = data_train\n",
    "x_test, y_test = data_test\n",
    "x, y = data\n",
    "orig_mean, orig_std = np.mean(y_train), np.std(y_train)\n",
    "y_train = (y_train-orig_mean)/orig_std\n",
    "y_test = (y_test-orig_mean)/orig_std\n",
    "\n",
    "X_train = tf.convert_to_tensor(x_train)\n",
    "X_full = tf.convert_to_tensor(x)\n",
    "Y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "adjacency_matrix = nx.to_numpy_array(G)  # Converts to NumPy adjacency matrix\n",
    "print(adjacency_matrix.shape)  # Check matrix size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0] # Number of training observations\n",
    "M = 50  # Number of inducing locations\n",
    "\n",
    "kernel = GraphDiffusionKernel(\n",
    "    adjacency_matrix=adjacency_matrix\n",
    ")\n",
    "Z = X_train[:M, :].numpy().copy()  # Initialize inducing locations to the first M inputs in the dataset\n",
    "\n",
    "m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, num_data=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svgp_training(X, Y, model, num_iterations=300, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Train SVGP model using Adam optimizer\n",
    "    \n",
    "    Args:\n",
    "        X: Training inputs\n",
    "        Y: Training outputs\n",
    "        model: SVGP model to train\n",
    "        num_iterations: Number of optimization iterations\n",
    "        learning_rate: Learning rate for Adam optimizer\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained SVGP model\n",
    "        losses: List of loss values during training\n",
    "    \"\"\"\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def optimization_step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model.training_loss((X, Y))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    losses = []\n",
    "    for i in tqdm(range(num_iterations), desc='Training SVGP'):\n",
    "        loss = optimization_step()\n",
    "        losses.append(loss.numpy())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Loss = {loss.numpy():.4f}\")\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "def svgp_evaluate(model, x_test, y_test, orig_std):\n",
    "    \"\"\"\n",
    "    Evaluate SVGP model on test data\n",
    "    \n",
    "    Args:\n",
    "        model: Trained SVGP model\n",
    "        x_test: Test inputs\n",
    "        y_test: Test outputs (standardized)\n",
    "        orig_std: Original standard deviation for denormalization\n",
    "    \n",
    "    Returns:\n",
    "        rmse: Root mean squared error\n",
    "        nlpd: Negative log predictive density\n",
    "    \"\"\"\n",
    "    # Get predictions (includes observation noise)\n",
    "    mean_y, var_y = model.predict_y(x_test)\n",
    "    \n",
    "    # Reshape predictions\n",
    "    mean_y = tf.reshape(mean_y, [-1])\n",
    "    var_y = tf.reshape(var_y, [-1])\n",
    "    \n",
    "    # Compute RMSE (denormalized)\n",
    "    rmse = float(orig_std * tf.sqrt(tf.reduce_mean((y_test[:, 0] - mean_y) ** 2)))\n",
    "    \n",
    "    # Compute NLPD\n",
    "    nlpd = -tf.reduce_sum(\n",
    "        tfp.distributions.Normal(loc=mean_y, scale=tf.sqrt(var_y)).log_prob(y_test[:, 0])\n",
    "    ).numpy()\n",
    "    \n",
    "    return rmse, nlpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVGP:   0%|          | 1/300 [00:04<20:41,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 397.3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVGP:  34%|███▎      | 101/300 [01:32<02:55,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: Loss = 363.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVGP:  67%|██████▋   | 201/300 [03:00<01:27,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200: Loss = 358.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SVGP: 100%|██████████| 300/300 [04:28<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train the SVGP model\n",
    "trained_model, losses = svgp_training(X_train, Y_train, m, num_iterations=300, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════════╤═════════╤══════════════════════════════════════════════════════╕\n",
      "│ name                     │ class     │ transform        │ prior   │ trainable   │ shape       │ dtype   │ value                                                │\n",
      "╞══════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════════╪═════════╪══════════════════════════════════════════════════════╡\n",
      "│ SVGP.kernel.beta         │ Parameter │ Softplus         │         │ True        │ ()          │ float64 │ 3.25914                                              │\n",
      "├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────────────────────────────────────────┤\n",
      "│ SVGP.kernel.sigma_f      │ Parameter │ Softplus         │         │ True        │ ()          │ float64 │ 0.3315358494831493                                   │\n",
      "├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────────────────────────────────────────┤\n",
      "│ SVGP.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()          │ float64 │ 1.00537                                              │\n",
      "├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────────────────────────────────────────┤\n",
      "│ SVGP.inducing_variable.Z │ Parameter │ Identity         │         │ True        │ (50, 1)     │ float64 │ [[537....                                            │\n",
      "├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────────────────────────────────────────┤\n",
      "│ SVGP.q_mu                │ Parameter │ Identity         │         │ True        │ (50, 1)     │ float64 │ [[0.08523565...                                      │\n",
      "├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────────────────────────────────────────┤\n",
      "│ SVGP.q_sqrt              │ Parameter │ FillTriangular   │         │ True        │ (1, 50, 50) │ float64 │ [[[9.79672906e-01, 0.00000000e+00, 0.00000000e+00... │\n",
      "╘══════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════════╧═════════╧══════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print_summary(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 16.402951419465193\n",
      "NLPD = 102.91814576946457\n"
     ]
    }
   ],
   "source": [
    "rmse, nlpd = svgp_evaluate(trained_model, x_test=x_test, y_test=y_test, orig_std=orig_std)\n",
    "print(f\"RMSE = {rmse}\")\n",
    "print(f\"NLPD = {nlpd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
