2025-08-10 12:24:30.145041: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-10 12:24:30.157787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754825070.197230 2409670 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754825070.222663 2409670 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754825070.303331 2409670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754825070.303380 2409670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754825070.303387 2409670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754825070.303392 2409670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-10 12:24:30.311531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/gpflow/versions.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
ðŸš€ Framework setup complete
   PyTorch device: cuda:0
   Number of GPUs: 2
   TensorFlow version: 2.19.0
   GPyTorch version: 1.14
ðŸ“‹ Configuration saved to: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/experiment_config_20250810_122451.json

==================== DATA SYNTHESIS ====================
ðŸŽ² Synthesizing ring graph data for all graph sizes...
   Feasible sizes (with dense): [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]
   Sparse-only sizes: []
Generating feasible datasets (dense+sparse):   0%|          | 0/9 [00:00<?, ?it/s]Generating feasible datasets (dense+sparse):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 21.75it/s]Generating feasible datasets (dense+sparse): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.92it/s]Generating feasible datasets (dense+sparse): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  6.93it/s]
   âœ“ Generated data for 32 nodes (dense: True)
   âœ“ Generated data for 64 nodes (dense: True)
   âœ“ Generated data for 128 nodes (dense: True)
   âœ“ Generated data for 256 nodes (dense: True)
   âœ“ Generated data for 512 nodes (dense: True)
   âœ“ Generated data for 1024 nodes (dense: True)
   âœ“ Generated data for 2048 nodes (dense: True)
   âœ“ Generated data for 4096 nodes (dense: True)
   âœ“ Generated data for 8192 nodes (dense: True)
Generating sparse-only datasets: 0it [00:00, ?it/s]Generating sparse-only datasets: 0it [00:00, ?it/s]
âœ… Data synthesis complete. Files stored in: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/synthetic_data

==================== RANDOM WALK SAMPLING ====================
ðŸš¶ Running RW sampling experiments...
Graph sizes:   0%|          | 0/9 [00:00<?, ?it/s]
Processing 32 nodes...
  Seed 1/5 (seed=42)
/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/../../efficient_graph_gp_sparse/preprocessor/graph_preprocessor.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)
  return torch.sparse_csr_tensor(
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  11%|â–ˆ         | 1/9 [00:02<00:18,  2.25s/it]
Processing 64 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  22%|â–ˆâ–ˆâ–       | 2/9 [00:05<00:20,  2.91s/it]
Processing 128 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:10<00:22,  3.68s/it]
Processing 256 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:18<00:26,  5.34s/it]
Processing 512 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:31<00:33,  8.29s/it]
Processing 1024 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [01:01<00:46, 15.54s/it]
Processing 2048 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [02:08<01:05, 32.60s/it]
Processing 4096 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [05:39<01:29, 89.22s/it]
Processing 8192 nodes...
  Seed 1/5 (seed=42)
  Seed 2/5 (seed=43)
  Seed 3/5 (seed=44)
  Seed 4/5 (seed=45)
  Seed 5/5 (seed=46)
Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [16:48<00:00, 270.54s/it]Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [16:48<00:00, 112.07s/it]
ðŸ“ rw_sampling results saved:
   Main file: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/rw_sampling_stats.csv
   Timestamped: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/rw_sampling_stats_20250810_124141.csv

âœ… RW sampling complete! Processed 45 experiments

==================== SPARSE GP EXPERIMENTS ====================
ðŸš€ Running sparse GP experiments on cuda:0...
Graph sizes:   0%|          | 0/9 [00:00<?, ?it/s]/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/linear_operator/utils/sparse.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if nonzero_indices.storage():
/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/linear_operator/utils/sparse.py:66: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  res = cls(index_tensor, value_tensor, interp_size)
/scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/venv/lib/python3.12/site-packages/linear_operator/utils/sparse.py:66: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:653.)
  res = cls(index_tensor, value_tensor, interp_size)
Graph sizes:  11%|â–ˆ         | 1/9 [00:27<03:38, 27.34s/it]Graph sizes:  22%|â–ˆâ–ˆâ–       | 2/9 [00:43<02:26, 20.98s/it]Graph sizes:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [01:02<01:58, 19.79s/it]Graph sizes:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [01:21<01:37, 19.51s/it]Graph sizes:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [01:41<01:19, 19.86s/it]Graph sizes:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [02:01<00:59, 19.68s/it]Graph sizes:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [02:19<00:38, 19.39s/it]Graph sizes:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [02:38<00:19, 19.06s/it]Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [02:58<00:00, 19.45s/it]Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [02:58<00:00, 19.84s/it]
  âœ“ 32 nodes, seed 42: RMSE=1.0799
  âœ“ 32 nodes, seed 43: RMSE=1.0012
  âœ“ 32 nodes, seed 44: RMSE=0.7184
  âœ“ 32 nodes, seed 45: RMSE=0.7706
  âœ“ 32 nodes, seed 46: RMSE=0.5993
  âœ“ 64 nodes, seed 42: RMSE=0.5847
  âœ“ 64 nodes, seed 43: RMSE=0.5636
  âœ“ 64 nodes, seed 44: RMSE=0.5678
  âœ“ 64 nodes, seed 45: RMSE=0.5796
  âœ“ 64 nodes, seed 46: RMSE=0.6765
  âœ“ 128 nodes, seed 42: RMSE=0.5389
  âœ“ 128 nodes, seed 43: RMSE=0.4639
  âœ“ 128 nodes, seed 44: RMSE=0.4429
  âœ“ 128 nodes, seed 45: RMSE=0.4878
  âœ“ 128 nodes, seed 46: RMSE=0.5779
  âœ“ 256 nodes, seed 42: RMSE=0.7042
  âœ“ 256 nodes, seed 43: RMSE=0.6174
  âœ“ 256 nodes, seed 44: RMSE=0.6395
  âœ“ 256 nodes, seed 45: RMSE=0.6753
  âœ“ 256 nodes, seed 46: RMSE=0.6497
  âœ“ 512 nodes, seed 42: RMSE=0.5364
  âœ“ 512 nodes, seed 43: RMSE=0.5711
  âœ“ 512 nodes, seed 44: RMSE=0.5432
  âœ“ 512 nodes, seed 45: RMSE=0.7458
  âœ“ 512 nodes, seed 46: RMSE=0.5997
  âœ“ 1024 nodes, seed 42: RMSE=0.7129
  âœ“ 1024 nodes, seed 43: RMSE=0.5599
  âœ“ 1024 nodes, seed 44: RMSE=0.5569
  âœ“ 1024 nodes, seed 45: RMSE=0.5463
  âœ“ 1024 nodes, seed 46: RMSE=0.5404
  âœ“ 2048 nodes, seed 42: RMSE=0.5505
  âœ“ 2048 nodes, seed 43: RMSE=0.5959
  âœ“ 2048 nodes, seed 44: RMSE=0.6361
  âœ“ 2048 nodes, seed 45: RMSE=0.5582
  âœ“ 2048 nodes, seed 46: RMSE=0.5863
  âœ“ 4096 nodes, seed 42: RMSE=0.5704
  âœ“ 4096 nodes, seed 43: RMSE=0.5313
  âœ“ 4096 nodes, seed 44: RMSE=0.6016
  âœ“ 4096 nodes, seed 45: RMSE=0.6309
  âœ“ 4096 nodes, seed 46: RMSE=0.6097
  âœ“ 8192 nodes, seed 42: RMSE=0.5975
  âœ“ 8192 nodes, seed 43: RMSE=0.6036
  âœ“ 8192 nodes, seed 44: RMSE=0.6118
  âœ“ 8192 nodes, seed 45: RMSE=1.0210
  âœ“ 8192 nodes, seed 46: RMSE=0.6303
ðŸ“ sparse_gp_scaling results saved:
   Main file: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/sparse_gp_scaling_stats.csv
   Timestamped: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/sparse_gp_scaling_stats_20250810_124440.csv
âœ… Sparse GP scaling complete! Processed 45 experiments

==================== DENSE GP EXPERIMENTS ====================
ðŸš€ Running dense GP experiments...
Graph sizes:   0%|          | 0/9 [00:00<?, ?it/s]I0000 00:00:1754826280.911484 2409670 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9591 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5
I0000 00:00:1754826280.912888 2409670 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9617 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754826282.729040 2409670 cuda_solvers.cc:175] Creating GpuSolver handles for stream 0x7123d520
Graph sizes:  11%|â–ˆ         | 1/9 [00:11<01:34, 11.83s/it]Graph sizes:  22%|â–ˆâ–ˆâ–       | 2/9 [00:20<01:10, 10.00s/it]Graph sizes:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:29<00:56,  9.36s/it]Graph sizes:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:37<00:44,  8.98s/it]Graph sizes:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:46<00:35,  8.84s/it]Graph sizes:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [01:00<00:32, 10.82s/it]Graph sizes:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [01:42<00:41, 20.82s/it]Graph sizes:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [05:23<01:24, 84.61s/it]Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [32:14<00:00, 561.79s/it]Graph sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [32:14<00:00, 214.94s/it]
    Loaded pre-computed dense step matrices with shape (32, 32, 3)
  âœ“ 32 nodes, seed 42: RMSE=0.1808
    Loaded pre-computed dense step matrices with shape (32, 32, 3)
  âœ“ 32 nodes, seed 43: RMSE=0.1873
    Loaded pre-computed dense step matrices with shape (32, 32, 3)
  âœ“ 32 nodes, seed 44: RMSE=0.2552
    Loaded pre-computed dense step matrices with shape (32, 32, 3)
  âœ“ 32 nodes, seed 45: RMSE=0.3221
    Loaded pre-computed dense step matrices with shape (32, 32, 3)
  âœ“ 32 nodes, seed 46: RMSE=0.2721
    Loaded pre-computed dense step matrices with shape (64, 64, 3)
  âœ“ 64 nodes, seed 42: RMSE=0.1670
    Loaded pre-computed dense step matrices with shape (64, 64, 3)
  âœ“ 64 nodes, seed 43: RMSE=0.1315
    Loaded pre-computed dense step matrices with shape (64, 64, 3)
  âœ“ 64 nodes, seed 44: RMSE=0.1982
    Loaded pre-computed dense step matrices with shape (64, 64, 3)
  âœ“ 64 nodes, seed 45: RMSE=0.1969
    Loaded pre-computed dense step matrices with shape (64, 64, 3)
  âœ“ 64 nodes, seed 46: RMSE=0.1833
    Loaded pre-computed dense step matrices with shape (128, 128, 3)
  âœ“ 128 nodes, seed 42: RMSE=0.2310
    Loaded pre-computed dense step matrices with shape (128, 128, 3)
  âœ“ 128 nodes, seed 43: RMSE=0.2080
    Loaded pre-computed dense step matrices with shape (128, 128, 3)
  âœ“ 128 nodes, seed 44: RMSE=0.2137
    Loaded pre-computed dense step matrices with shape (128, 128, 3)
  âœ“ 128 nodes, seed 45: RMSE=0.1888
    Loaded pre-computed dense step matrices with shape (128, 128, 3)
  âœ“ 128 nodes, seed 46: RMSE=0.2058
    Loaded pre-computed dense step matrices with shape (256, 256, 3)
  âœ“ 256 nodes, seed 42: RMSE=0.2865
    Loaded pre-computed dense step matrices with shape (256, 256, 3)
  âœ“ 256 nodes, seed 43: RMSE=0.2882
    Loaded pre-computed dense step matrices with shape (256, 256, 3)
  âœ“ 256 nodes, seed 44: RMSE=0.2539
    Loaded pre-computed dense step matrices with shape (256, 256, 3)
  âœ“ 256 nodes, seed 45: RMSE=0.3174
    Loaded pre-computed dense step matrices with shape (256, 256, 3)
  âœ“ 256 nodes, seed 46: RMSE=0.2864
    Loaded pre-computed dense step matrices with shape (512, 512, 3)
  âœ“ 512 nodes, seed 42: RMSE=0.2774
    Loaded pre-computed dense step matrices with shape (512, 512, 3)
  âœ“ 512 nodes, seed 43: RMSE=0.2864
    Loaded pre-computed dense step matrices with shape (512, 512, 3)
  âœ“ 512 nodes, seed 44: RMSE=0.2930
    Loaded pre-computed dense step matrices with shape (512, 512, 3)
  âœ“ 512 nodes, seed 45: RMSE=0.2904
    Loaded pre-computed dense step matrices with shape (512, 512, 3)
  âœ“ 512 nodes, seed 46: RMSE=0.2717
    Loaded pre-computed dense step matrices with shape (1024, 1024, 3)
  âœ“ 1024 nodes, seed 42: RMSE=0.2438
    Loaded pre-computed dense step matrices with shape (1024, 1024, 3)
  âœ“ 1024 nodes, seed 43: RMSE=0.2638
    Loaded pre-computed dense step matrices with shape (1024, 1024, 3)
  âœ“ 1024 nodes, seed 44: RMSE=0.2313
    Loaded pre-computed dense step matrices with shape (1024, 1024, 3)
  âœ“ 1024 nodes, seed 45: RMSE=0.2577
    Loaded pre-computed dense step matrices with shape (1024, 1024, 3)
  âœ“ 1024 nodes, seed 46: RMSE=0.2422
    Loaded pre-computed dense step matrices with shape (2048, 2048, 3)
  âœ“ 2048 nodes, seed 42: RMSE=0.2702
    Loaded pre-computed dense step matrices with shape (2048, 2048, 3)
  âœ“ 2048 nodes, seed 43: RMSE=0.2852
    Loaded pre-computed dense step matrices with shape (2048, 2048, 3)
  âœ“ 2048 nodes, seed 44: RMSE=0.2589
    Loaded pre-computed dense step matrices with shape (2048, 2048, 3)
  âœ“ 2048 nodes, seed 45: RMSE=0.2768
    Loaded pre-computed dense step matrices with shape (2048, 2048, 3)
  âœ“ 2048 nodes, seed 46: RMSE=0.2634
    Loaded pre-computed dense step matrices with shape (4096, 4096, 3)
  âœ“ 4096 nodes, seed 42: RMSE=0.2752
    Loaded pre-computed dense step matrices with shape (4096, 4096, 3)
  âœ“ 4096 nodes, seed 43: RMSE=0.2814
    Loaded pre-computed dense step matrices with shape (4096, 4096, 3)
  âœ“ 4096 nodes, seed 44: RMSE=0.2918
    Loaded pre-computed dense step matrices with shape (4096, 4096, 3)
  âœ“ 4096 nodes, seed 45: RMSE=0.2810
    Loaded pre-computed dense step matrices with shape (4096, 4096, 3)
  âœ“ 4096 nodes, seed 46: RMSE=0.2810
    Loaded pre-computed dense step matrices with shape (8192, 8192, 3)
  âœ“ 8192 nodes, seed 42: RMSE=0.3000
    Loaded pre-computed dense step matrices with shape (8192, 8192, 3)
  âœ“ 8192 nodes, seed 43: RMSE=0.3008
    Loaded pre-computed dense step matrices with shape (8192, 8192, 3)
  âœ“ 8192 nodes, seed 44: RMSE=0.2989
    Loaded pre-computed dense step matrices with shape (8192, 8192, 3)
  âœ“ 8192 nodes, seed 45: RMSE=0.2934
    Loaded pre-computed dense step matrices with shape (8192, 8192, 3)
  âœ“ 8192 nodes, seed 46: RMSE=0.2877
ðŸ“ dense_gp_scaling results saved:
   Main file: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/dense_gp_scaling_stats.csv
   Timestamped: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats/dense_gp_scaling_stats_20250810_131655.csv
âœ… Dense GP scaling complete! Processed 45 experiments

================================================================================
EXPERIMENT SUMMARY
================================================================================

ðŸ“Š Random Walk Performance:
   â€¢ Average Speedup: 8.65x
   â€¢ Average Compression: 302.8x
   â€¢ Total Experiments: 45
   â€¢ Sparse-only (large graphs): 0 experiments

ðŸš€ Sparse GP Performance:
   â€¢ Graph sizes: [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]
   â€¢ Average RMSE: 0.6264
   â€¢ Average training time: 3.47s
   â€¢ Total experiments: 45

ðŸš€ Dense GP Performance:
   â€¢ Graph sizes: [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]
   â€¢ Average RMSE: 0.2551
   â€¢ Average training time: 40.56s
   â€¢ Total experiments: 45

âš–ï¸  Dense vs Sparse Comparison (common sizes: [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]):
   â€¢ Speed improvement: 11.74x
   â€¢ RMSE difference: 0.3713

ðŸŽ‰ Scaling experiment completed successfully!
ðŸ“ Results saved to: /scratches/cartwright/mz473/Efficient-Gaussian-Process-on-Graphs/experiments_sparse/scaling_exp/stats
